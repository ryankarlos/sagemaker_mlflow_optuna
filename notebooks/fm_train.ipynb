{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# FM Training Notebook\n",
    "\n",
    "This notebook is executed as a SageMaker notebook job for FM Optuna training.\n",
    "Parameters are injected by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters - these will be overwritten by the pipeline\n",
    "config_name = \"default\"\n",
    "n_users = \"5000\"\n",
    "n_games = \"100\"\n",
    "n_days = \"180\"\n",
    "max_trials = \"20\"\n",
    "early_stopping = \"5\"\n",
    "experiment_name = \"fm_gambling_optuna\"\n",
    "use_feature_store = \"false\"\n",
    "project_name = \"fm-gambling-recommender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Get AWS account info\n",
    "sts = boto3.client(\"sts\")\n",
    "account_id = sts.get_caller_identity()[\"Account\"]\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "print(f\"AWS Account: {account_id}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string params to appropriate types\n",
    "n_users = int(n_users)\n",
    "n_games = int(n_games)\n",
    "n_days = int(n_days)\n",
    "max_trials = int(max_trials)\n",
    "early_stopping = int(early_stopping)\n",
    "use_feature_store = use_feature_store.lower() == \"true\"\n",
    "\n",
    "print(f\"Config: {config_name}\")\n",
    "print(f\"Users: {n_users}, Games: {n_games}, Days: {n_days}\")\n",
    "print(f\"Max trials: {max_trials}, Early stopping: {early_stopping}\")\n",
    "print(f\"Use Feature Store: {use_feature_store}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "from data.simulate_gambling_data import generate_gambling_dataset\n",
    "from steps.preprocess.fm_encoding import FMEncoder, create_user_item_matrix\n",
    "from steps.train.factorization_machines import LocalFMSimulator\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Generating gambling dataset...\")\n",
    "users, games, interactions, _ = generate_gambling_dataset(\n",
    "    n_users=n_users,\n",
    "    n_games=n_games,\n",
    "    n_days=n_days,\n",
    "    avg_sessions_per_user=30,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(users)} users, {len(games)} games, {len(interactions)} interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Ingest to Feature Store (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_feature_store:\n",
    "    from utils.feature_store import FeatureStoreManager\n",
    "    \n",
    "    fs_manager = FeatureStoreManager(project_name=project_name)\n",
    "    print(f\"Feature Store Manager initialized for account {fs_manager.account_id}\")\n",
    "    \n",
    "    # Check feature group status\n",
    "    fg_status = fs_manager.describe_feature_groups()\n",
    "    for name, status in fg_status.items():\n",
    "        print(f\"  {name}: {status['status']}\")\n",
    "    \n",
    "    # Ingest features\n",
    "    print(\"\\nIngesting features...\")\n",
    "    fs_manager.ingest_all_features(users, games, interactions, wait=True)\n",
    "    print(\"Feature Store ingestion complete!\")\n",
    "else:\n",
    "    print(\"Skipping Feature Store ingestion (use_feature_store=false)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by date\n",
    "train_days = int(n_days * 0.8)\n",
    "interactions[\"summary_date\"] = pd.to_datetime(interactions[\"summary_date\"])\n",
    "min_date = interactions[\"summary_date\"].min()\n",
    "cutoff_date = min_date + pd.Timedelta(days=train_days)\n",
    "\n",
    "train_df = interactions[interactions[\"summary_date\"] <= cutoff_date].copy()\n",
    "valid_df = interactions[interactions[\"summary_date\"] > cutoff_date].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Validation: {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode features\n",
    "encoder = FMEncoder()\n",
    "categorical_cols = [\"game_type\", \"vip_tier\", \"region\"]\n",
    "\n",
    "train_features = train_df.merge(users, on=\"user_id\").merge(games, on=\"game_id\")\n",
    "valid_features = valid_df.merge(users, on=\"user_id\").merge(games, on=\"game_id\")\n",
    "\n",
    "X_train, y_train = encoder.fit_transform(\n",
    "    train_features, target_col=\"bet_qty\", categorical_cols=categorical_cols\n",
    ")\n",
    "X_valid, y_valid = encoder.transform(\n",
    "    valid_features, target_col=\"bet_qty\", categorical_cols=categorical_cols\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Run Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"X_train\": X_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"X_valid\": X_valid,\n",
    "    \"y_valid\": y_valid,\n",
    "}\n",
    "\n",
    "def objective(trial, data):\n",
    "    \"\"\"Optuna objective function.\"\"\"\n",
    "    with mlflow.start_run(run_name=f\"Trial-{trial.number}\", nested=True):\n",
    "        num_factors = trial.suggest_int(\"num_factors\", 8, 64)\n",
    "        epochs = trial.suggest_int(\"epochs\", 10, 30)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True)\n",
    "\n",
    "        mlflow.log_params({\n",
    "            \"num_factors\": num_factors,\n",
    "            \"epochs\": epochs,\n",
    "            \"learning_rate\": learning_rate,\n",
    "        })\n",
    "\n",
    "        model = LocalFMSimulator(\n",
    "            num_factors=num_factors,\n",
    "            epochs=epochs,\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "        model.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "\n",
    "        train_rmse = model.score(data[\"X_train\"], data[\"y_train\"])\n",
    "        valid_rmse = model.score(data[\"X_valid\"], data[\"y_valid\"])\n",
    "\n",
    "        mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "        mlflow.log_metric(\"valid_rmse\", valid_rmse)\n",
    "\n",
    "        logger.info(f\"Trial {trial.number}: RMSE={valid_rmse:.4f}\")\n",
    "        return -valid_rmse\n",
    "\n",
    "\n",
    "def early_stopping_callback(study, trial, rounds=5):\n",
    "    \"\"\"Early stopping callback.\"\"\"\n",
    "    if len(study.trials) < rounds:\n",
    "        return\n",
    "    recent = [t.value for t in study.trials[-rounds:] if t.value is not None]\n",
    "    if len(recent) < rounds:\n",
    "        return\n",
    "    if study.best_value is not None and max(recent) <= study.best_value - 0.001:\n",
    "        study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MLflow\n",
    "mlflow.set_experiment(experiment_name)\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "study_name = f\"fm_{config_name}_{current_time}\"\n",
    "\n",
    "# Create results directory\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "storage_path = f\"results/optuna_{study_name}.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=f\"FM-{config_name}-{current_time}\"):\n",
    "    mlflow.log_params({\n",
    "        \"config_name\": config_name,\n",
    "        \"n_users\": n_users,\n",
    "        \"n_games\": n_games,\n",
    "        \"n_days\": n_days,\n",
    "        \"max_trials\": max_trials,\n",
    "        \"aws_account_id\": account_id,\n",
    "        \"aws_region\": region,\n",
    "        \"use_feature_store\": use_feature_store,\n",
    "    })\n",
    "\n",
    "    # Create study\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=study_name,\n",
    "        storage=f\"sqlite:///{storage_path}\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    fn = partial(objective, data=data)\n",
    "    es_callback = partial(early_stopping_callback, rounds=early_stopping)\n",
    "\n",
    "    study.optimize(\n",
    "        fn,\n",
    "        n_trials=max_trials,\n",
    "        callbacks=[es_callback],\n",
    "        gc_after_trial=True,\n",
    "    )\n",
    "\n",
    "    # Log results\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study.best_params.items()})\n",
    "    mlflow.log_metric(\"best_valid_rmse\", -study.best_value)\n",
    "\n",
    "    # Save artifacts\n",
    "    trials_df = study.trials_dataframe()\n",
    "    trials_path = f\"results/{study_name}_trials.parquet\"\n",
    "    trials_df.to_parquet(trials_path)\n",
    "    mlflow.log_artifact(trials_path, artifact_path=\"trials\")\n",
    "    mlflow.log_artifact(storage_path, artifact_path=\"optuna_db\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBest RMSE: {-study.best_value:.4f}\")\n",
    "print(f\"Best parameters:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
