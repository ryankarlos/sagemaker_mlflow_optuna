{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# FM Training Notebook\n",
    "\n",
    "This notebook is executed as a SageMaker notebook job for FM Optuna training.\n",
    "Parameters are injected by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4de121-086b-42f0-8aa4-42fb597d77b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from data.simulate_gambling_data import generate_gambling_dataset\n",
    "from scripts.fm_encoding import FMEncoder, create_user_item_matrix\n",
    "from scripts.factorization_machines import LocalFMSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters - set parameter cell tag here to be overridden by notebook pipeline\n",
    "n_users = \"5000\"\n",
    "n_games = \"100\"\n",
    "n_days = \"180\"\n",
    "max_trials = \"20\"\n",
    "early_stopping = \"5\"\n",
    "experiment_name = \"fm_gambling_optuna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Account: 376337229415\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get AWS account info\n",
    "sts = boto3.client(\"sts\")\n",
    "account_id = sts.get_caller_identity()[\"Account\"]\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "print(f\"AWS Account: {account_id}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 5000, Games: 100, Days: 180\n",
      "Max trials: 20, Early stopping: 5\n"
     ]
    }
   ],
   "source": [
    "# Convert string params to appropriate types\n",
    "n_users = int(n_users)\n",
    "n_games = int(n_games)\n",
    "n_days = int(n_days)\n",
    "max_trials = int(max_trials)\n",
    "early_stopping = int(early_stopping)\n",
    "\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "mlflow.set_tracking_uri(\"arn:aws:sagemaker:us-east-1:376337229415:mlflow-tracking-server/fm-gambling-recommender-dev-mlflow\")\n",
    "\n",
    "print(f\"Users: {n_users}, Games: {n_games}, Days: {n_days}\")\n",
    "print(f\"Max trials: {max_trials}, Early stopping: {early_stopping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating gambling dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5000 users, 100 games, 150000 interactions\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Generating gambling dataset...\")\n",
    "users, games, interactions, _ = generate_gambling_dataset(\n",
    "    n_users=n_users,\n",
    "    n_games=n_games,\n",
    "    n_days=n_days,\n",
    "    avg_sessions_per_user=30,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(users)} users, {len(games)} games, {len(interactions)} interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 120486, Validation: 29514\n"
     ]
    }
   ],
   "source": [
    "# Split by date\n",
    "train_days = int(n_days * 0.8)\n",
    "interactions[\"summary_date\"] = pd.to_datetime(interactions[\"summary_date\"])\n",
    "min_date = interactions[\"summary_date\"].min()\n",
    "cutoff_date = min_date + pd.Timedelta(days=train_days)\n",
    "\n",
    "train_df = interactions[interactions[\"summary_date\"] <= cutoff_date].copy()\n",
    "valid_df = interactions[interactions[\"summary_date\"] > cutoff_date].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Validation: {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120486, 4911)\n",
      "X_valid shape: (29514, 4911)\n"
     ]
    }
   ],
   "source": [
    "# Encode features\n",
    "encoder = FMEncoder()\n",
    "categorical_cols = [\"game_type\", \"vip_tier\", \"region\"]\n",
    "\n",
    "train_features = train_df.merge(users, on=\"user_id\").merge(games, on=\"game_id\")\n",
    "valid_features = valid_df.merge(users, on=\"user_id\").merge(games, on=\"game_id\")\n",
    "\n",
    "X_train, y_train = encoder.fit_transform(\n",
    "    train_features, target_col=\"bet_qty\", categorical_cols=categorical_cols\n",
    ")\n",
    "X_valid, y_valid = encoder.transform(\n",
    "    valid_features, target_col=\"bet_qty\", categorical_cols=categorical_cols\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Run Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"X_train\": X_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"X_valid\": X_valid,\n",
    "    \"y_valid\": y_valid,\n",
    "}\n",
    "\n",
    "def objective(trial, data):\n",
    "    \"\"\"Optuna objective function.\"\"\"\n",
    "    with mlflow.start_run(run_name=f\"Trial-{trial.number}\", nested=True):\n",
    "        num_factors = trial.suggest_int(\"num_factors\", 8, 64)\n",
    "        epochs = trial.suggest_int(\"epochs\", 10, 30)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True)\n",
    "\n",
    "        mlflow.log_params({\n",
    "            \"num_factors\": num_factors,\n",
    "            \"epochs\": epochs,\n",
    "            \"learning_rate\": learning_rate,\n",
    "        })\n",
    "\n",
    "        model = LocalFMSimulator(\n",
    "            num_factors=num_factors,\n",
    "            epochs=epochs,\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "        model.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "\n",
    "        train_rmse = model.score(data[\"X_train\"], data[\"y_train\"])\n",
    "        valid_rmse = model.score(data[\"X_valid\"], data[\"y_valid\"])\n",
    "\n",
    "        mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "        mlflow.log_metric(\"valid_rmse\", valid_rmse)\n",
    "\n",
    "        logger.info(f\"Trial {trial.number}: RMSE={valid_rmse:.4f}\")\n",
    "        return -valid_rmse\n",
    "\n",
    "\n",
    "def early_stopping_callback(study, trial, rounds=5):\n",
    "    \"\"\"Early stopping callback.\"\"\"\n",
    "    if len(study.trials) < rounds:\n",
    "        return\n",
    "    recent = [t.value for t in study.trials[-rounds:] if t.value is not None]\n",
    "    if len(recent) < rounds:\n",
    "        return\n",
    "    if study.best_value is not None and max(recent) <= study.best_value - 0.001:\n",
    "        study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup MLflow\n",
    "mlflow.set_experiment(experiment_name)\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "study_name = f\"fm_demo_{current_time}\"\n",
    "\n",
    "# Create results directory\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "storage_path = f\"results/optuna_{study_name}.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/02 20:35:21 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/01/02 20:35:21 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "[I 2026-01-02 20:35:22,806] A new study created in RDB with name: fm_demo_20260102_203449\n",
      "2026/01/02 20:35:22 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/01/02 20:35:22 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "INFO:scripts.factorization_machines:Epoch 0, RMSE: 27.2414\n",
      "INFO:scripts.factorization_machines:Epoch 5, RMSE: 26.8940\n",
      "INFO:scripts.factorization_machines:Epoch 10, RMSE: 26.8137\n",
      "INFO:__main__:Trial 0: RMSE=26.6244\n",
      "2026/01/02 20:44:39 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2026/01/02 20:44:39 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2026-01-02 20:44:39,601] Trial 0 finished with value: -26.624366893531093 and parameters: {'num_factors': 20, 'epochs': 14, 'learning_rate': 0.001137998575727264}. Best is trial 0 with value: -26.624366893531093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run Trial-0 at: https://us-east-1.experiments.sagemaker.aws/#/experiments/1/runs/ca34406582c441ac8a578bf61eebddd9\n",
      "ðŸ§ª View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/02 20:44:39 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/01/02 20:44:39 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "INFO:scripts.factorization_machines:Epoch 0, RMSE: 27.3523\n",
      "INFO:scripts.factorization_machines:Epoch 5, RMSE: 27.0347\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "with mlflow.start_run(run_name=f\"FM-demo-{int(time.time())}\"):\n",
    "    mlflow.log_params({\n",
    "        \"n_users\": n_users,\n",
    "        \"n_games\": n_games,\n",
    "        \"n_days\": n_days,\n",
    "        \"max_trials\": max_trials,\n",
    "        \"aws_account_id\": account_id,\n",
    "        \"aws_region\": region,\n",
    "    })\n",
    "\n",
    "    # Create study\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=study_name,\n",
    "        storage=f\"sqlite:///{storage_path}\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    fn = partial(objective, data=data)\n",
    "    es_callback = partial(early_stopping_callback, rounds=early_stopping)\n",
    "\n",
    "    study.optimize(\n",
    "        fn,\n",
    "        n_trials=max_trials,\n",
    "        callbacks=[es_callback],\n",
    "        gc_after_trial=True,\n",
    "    )\n",
    "\n",
    "    # Log results\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study.best_params.items()})\n",
    "    mlflow.log_metric(\"best_valid_rmse\", -study.best_value)\n",
    "\n",
    "    # Save artifacts\n",
    "    trials_df = study.trials_dataframe()\n",
    "    trials_path = f\"results/{study_name}_trials.parquet\"\n",
    "    trials_df.to_parquet(trials_path)\n",
    "    mlflow.log_artifact(trials_path, artifact_path=\"trials\")\n",
    "    mlflow.log_artifact(storage_path, artifact_path=\"optuna_db\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"\\nBest RMSE: {-study.best_value:.4f}\")\n",
    "print(f\"Best parameters:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
