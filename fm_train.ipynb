{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# FM Training - Brand-Specific\n",
    "\n",
    "Factorization Machines training with MLflow & Optuna.\n",
    "Hyperparameter ranges vary per brand, data size is static."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "9d4de121-086b-42f0-8aa4-42fb597d77b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
=======
   "execution_count": null,
   "id": "1",
   "metadata": {},
>>>>>>> f8297f4 (add simplfiied scripts)
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Setup\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "region = session.boto_region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters - set parameter cell tag here to be overridden by notebook pipeline\n",
    "n_users = \"5000\"\n",
    "n_games = \"100\"\n",
    "n_days = \"180\"\n",
    "max_trials = \"20\"\n",
    "early_stopping = \"5\"\n",
    "experiment_name = \"fm_gambling_optuna\""
=======
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": ["parameters"]
   },
   "outputs": [],
   "source": [
    "# Parameters - injected by pipeline per brand\n",
    "brand = \"betmax\"\n",
    "max_trials = \"10\"\n",
    "early_stopping = \"3\"\n",
    "num_factors_min = \"16\"\n",
    "num_factors_max = \"64\"\n",
    "epochs_min = \"10\"\n",
    "epochs_max = \"30\"\n",
    "experiment_name = \"fm_gambling_demo\"\n",
    "project_name = \"fm-gambling-recommender\""
>>>>>>> f8297f4 (add simplfiied scripts)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Account: 376337229415\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get AWS account info\n",
    "sts = boto3.client(\"sts\")\n",
    "account_id = sts.get_caller_identity()[\"Account\"]\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "print(f\"AWS Account: {account_id}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 5000, Games: 100, Days: 180\n",
      "Max trials: 20, Early stopping: 5\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
>>>>>>> f8297f4 (add simplfiied scripts)
   "source": [
    "# Convert params\n",
    "max_trials = int(max_trials)\n",
    "early_stopping = int(early_stopping)\n",
    "num_factors_min = int(num_factors_min)\n",
    "num_factors_max = int(num_factors_max)\n",
    "epochs_min = int(epochs_min)\n",
    "epochs_max = int(epochs_max)\n",
    "\n",
<<<<<<< HEAD
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "mlflow.set_tracking_uri(\"arn:aws:sagemaker:us-east-1:376337229415:mlflow-tracking-server/fm-gambling-recommender-dev-mlflow\")\n",
    "\n",
    "print(f\"Users: {n_users}, Games: {n_games}, Days: {n_days}\")\n",
    "print(f\"Max trials: {max_trials}, Early stopping: {early_stopping}\")"
=======
    "# Static data size for demo\n",
    "N_USERS = 500\n",
    "N_GAMES = 50\n",
    "\n",
    "print(f\"Brand: {brand}\")\n",
    "print(f\"Trials: {max_trials}, Early stop: {early_stopping}\")\n",
    "print(f\"Factors: {num_factors_min}-{num_factors_max}\")\n",
    "print(f\"Epochs: {epochs_min}-{epochs_max}\")"
>>>>>>> f8297f4 (add simplfiied scripts)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> f8297f4 (add simplfiied scripts)
   "id": "4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MLflow setup\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"arn:aws:sagemaker:{region}:{account_id}:mlflow-tracking-server/{project_name}-dev-mlflow\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"MLflow experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating gambling dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5000 users, 100 games, 150000 interactions\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
>>>>>>> f8297f4 (add simplfiied scripts)
   "source": [
    "from scripts.simulate_gambling_data import generate_demo_data\n",
    "\n",
    "X_train, y_train, X_test, y_test = generate_demo_data(\n",
    "    n_users=N_USERS,\n",
    "    n_games=N_GAMES,\n",
    "    brand=brand,\n",
    ")\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "prefix = f\"fm-{brand}\"\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}, Features: {n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.fm_sagemaker import write_to_s3\n",
    "\n",
    "train_path = write_to_s3(X_train, y_train, bucket, prefix, \"train/train.protobuf\")\n",
    "test_path = write_to_s3(X_test, y_test, bucket, prefix, \"test/test.protobuf\")\n",
    "output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "print(f\"Data uploaded to s3://{bucket}/{prefix}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "id": "10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 120486, Validation: 29514\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
>>>>>>> f8297f4 (add simplfiied scripts)
   "source": [
    "from scripts.fm_sagemaker import train_fm_model\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective with brand-specific hyperparameter ranges.\"\"\"\n",
    "    \n",
    "    num_factors = trial.suggest_int(\"num_factors\", num_factors_min, num_factors_max)\n",
    "    epochs = trial.suggest_int(\"epochs\", epochs_min, epochs_max)\n",
    "    mini_batch_size = trial.suggest_categorical(\"mini_batch_size\", [100, 200, 500])\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"{brand}-trial-{trial.number}\", nested=True):\n",
    "        mlflow.log_params({\n",
    "            \"brand\": brand,\n",
    "            \"num_factors\": num_factors,\n",
    "            \"epochs\": epochs,\n",
    "            \"mini_batch_size\": mini_batch_size,\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            fm = train_fm_model(\n",
    "                train_path=train_path,\n",
    "                test_path=test_path,\n",
    "                output_path=f\"{output_path}/trial-{trial.number}\",\n",
    "                role=role,\n",
    "                n_features=n_features,\n",
    "                num_factors=num_factors,\n",
    "                epochs=epochs,\n",
    "                mini_batch_size=mini_batch_size,\n",
    "            )\n",
    "            \n",
    "            # Get test RMSE\n",
    "            job_name = fm.latest_training_job.name\n",
    "            sm = boto3.client(\"sagemaker\")\n",
    "            metrics = sm.describe_training_job(TrainingJobName=job_name)\n",
    "            \n",
    "            test_rmse = 999.0\n",
    "            for m in metrics.get(\"FinalMetricDataList\", []):\n",
    "                if m[\"MetricName\"] == \"test:rmse\":\n",
    "                    test_rmse = m[\"Value\"]\n",
    "                    break\n",
    "            \n",
    "            mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "            print(f\"Trial {trial.number}: RMSE={test_rmse:.4f}\")\n",
    "            return test_rmse\n",
    "            \n",
    "        except Exception as e:\n",
    "            mlflow.log_param(\"error\", str(e)[:200])\n",
    "            return 999.0\n",
    "\n",
    "\n",
    "def early_stop_callback(study, trial):\n",
    "    if len(study.trials) < early_stopping:\n",
    "        return\n",
    "    recent = [t.value for t in study.trials[-early_stopping:] if t.value and t.value < 999]\n",
    "    if len(recent) >= early_stopping and study.best_value:\n",
    "        if min(recent) >= study.best_value:\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120486, 4911)\n",
      "X_valid shape: (29514, 4911)\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
>>>>>>> f8297f4 (add simplfiied scripts)
   "source": [
    "# Run optimization\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"{brand}-{timestamp}\"):\n",
    "    mlflow.log_params({\n",
    "        \"brand\": brand,\n",
    "        \"n_users\": N_USERS,\n",
    "        \"n_games\": N_GAMES,\n",
    "        \"max_trials\": max_trials,\n",
    "        \"num_factors_range\": f\"{num_factors_min}-{num_factors_max}\",\n",
    "        \"epochs_range\": f\"{epochs_min}-{epochs_max}\",\n",
    "    })\n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=f\"fm_{brand}_{timestamp}\")\n",
    "    study.optimize(objective, n_trials=max_trials, callbacks=[early_stop_callback])\n",
    "    \n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study.best_params.items()})\n",
    "    mlflow.log_metric(\"best_rmse\", study.best_value)\n",
    "    \n",
    "    print(f\"\\nBest RMSE: {study.best_value:.4f}\")\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Setup MLflow\n",
    "mlflow.set_experiment(experiment_name)\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "study_name = f\"fm_demo_{current_time}\"\n",
    "\n",
    "# Create results directory\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "storage_path = f\"results/optuna_{study_name}.db\""
=======
    "optuna.visualization.plot_param_importances(study)"
>>>>>>> f8297f4 (add simplfiied scripts)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/02 20:35:21 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/01/02 20:35:21 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "[I 2026-01-02 20:35:22,806] A new study created in RDB with name: fm_demo_20260102_203449\n",
      "2026/01/02 20:35:22 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/01/02 20:35:22 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "INFO:scripts.factorization_machines:Epoch 0, RMSE: 27.2414\n",
      "INFO:scripts.factorization_machines:Epoch 5, RMSE: 26.8940\n",
      "INFO:scripts.factorization_machines:Epoch 10, RMSE: 26.8137\n",
      "INFO:__main__:Trial 0: RMSE=26.6244\n",
      "2026/01/02 20:44:39 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2026/01/02 20:44:39 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2026-01-02 20:44:39,601] Trial 0 finished with value: -26.624366893531093 and parameters: {'num_factors': 20, 'epochs': 14, 'learning_rate': 0.001137998575727264}. Best is trial 0 with value: -26.624366893531093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Trial-0 at: https://us-east-1.experiments.sagemaker.aws/#/experiments/1/runs/ca34406582c441ac8a578bf61eebddd9\n",
      "üß™ View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/02 20:44:39 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/01/02 20:44:39 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "INFO:scripts.factorization_machines:Epoch 0, RMSE: 27.3523\n",
      "INFO:scripts.factorization_machines:Epoch 5, RMSE: 27.0347\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import time\n",
    "\n",
    "with mlflow.start_run(run_name=f\"FM-demo-{int(time.time())}\"):\n",
    "    mlflow.log_params({\n",
    "        \"n_users\": n_users,\n",
    "        \"n_games\": n_games,\n",
    "        \"n_days\": n_days,\n",
    "        \"max_trials\": max_trials,\n",
    "        \"aws_account_id\": account_id,\n",
    "        \"aws_region\": region,\n",
    "    })\n",
    "\n",
    "    # Create study\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=study_name,\n",
    "        storage=f\"sqlite:///{storage_path}\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    fn = partial(objective, data=data)\n",
    "    es_callback = partial(early_stopping_callback, rounds=early_stopping)\n",
    "\n",
    "    study.optimize(\n",
    "        fn,\n",
    "        n_trials=max_trials,\n",
    "        callbacks=[es_callback],\n",
    "        gc_after_trial=True,\n",
    "    )\n",
    "\n",
    "    # Log results\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study.best_params.items()})\n",
    "    mlflow.log_metric(\"best_valid_rmse\", -study.best_value)\n",
    "\n",
    "    # Save artifacts\n",
    "    trials_df = study.trials_dataframe()\n",
    "    trials_path = f\"results/{study_name}_trials.parquet\"\n",
    "    trials_df.to_parquet(trials_path)\n",
    "    mlflow.log_artifact(trials_path, artifact_path=\"trials\")\n",
    "    mlflow.log_artifact(storage_path, artifact_path=\"optuna_db\")\n",
    "\n",
    "mlflow.end_run()"
=======
    "study.trials_dataframe()"
>>>>>>> f8297f4 (add simplfiied scripts)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=f\"{brand}-final\"):\n",
    "    mlflow.log_params({\"brand\": brand, **study.best_params})\n",
    "    \n",
    "    final_fm = train_fm_model(\n",
    "        train_path=train_path,\n",
    "        test_path=test_path,\n",
    "        output_path=f\"{output_path}/final\",\n",
    "        role=role,\n",
    "        n_features=n_features,\n",
    "        **study.best_params,\n",
    "    )\n",
    "    \n",
    "    mlflow.log_param(\"model_data\", final_fm.model_data)\n",
    "    print(f\"Final model: {final_fm.model_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"COMPLETE - {brand.upper()}\")\n",
    "print(f\"Best RMSE: {study.best_value:.4f}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "print(f\"{'='*50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
