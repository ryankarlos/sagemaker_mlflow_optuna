{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Multi-Model Hyperparameter Tuning with MLflow and Optuna\n",
    "\n",
    "XGBoost hyperparameter optimization using Optuna with MLflow child runs.\n",
    "Trains separate models per product category for electronics sales prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": ["parameters"]
   },
   "outputs": [],
   "source": [
    "# Experiment settings\n",
    "experiment_name = \"electronics-sales-tuning\"\n",
    "n_trials = 50\n",
    "\n",
    "# Data settings\n",
    "n_rows_per_category = 1000\n",
    "test_size = 0.25\n",
    "seed = 42\n",
    "\n",
    "# Categories to train (None = all)\n",
    "categories_to_train = None  # or [\"smartphones\", \"laptops\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Setup MLflow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_experiment(experiment_name: str) -> str:\n",
    "    \"\"\"Get existing experiment or create new one.\"\"\"\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if experiment:\n",
    "        return experiment.experiment_id\n",
    "    return mlflow.create_experiment(experiment_name)\n",
    "\n",
    "experiment_id = get_or_create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "print(f\"Experiment: {experiment_name} (ID: {experiment_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Load Electronics Sales Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.generate_electronics_sales_data import (\n",
    "    get_category_datasets,\n",
    "    prepare_features,\n",
    "    PRODUCT_CATEGORIES,\n",
    ")\n",
    "\n",
    "# Load datasets per category\n",
    "category_datasets = get_category_datasets(\n",
    "    n_rows_per_category=n_rows_per_category,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "# Filter categories if specified\n",
    "if categories_to_train:\n",
    "    category_datasets = {k: v for k, v in category_datasets.items() if k in categories_to_train}\n",
    "\n",
    "print(f\"Categories: {list(category_datasets.keys())}\")\n",
    "for cat, df in category_datasets.items():\n",
    "    print(f\"  {cat}: {len(df)} rows, target mean={df['units_sold'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train/valid splits for each category\n",
    "category_splits = {}\n",
    "for cat, df in category_datasets.items():\n",
    "    train_x, valid_x, train_y, valid_y = prepare_features(df, test_size=test_size, seed=seed)\n",
    "    category_splits[cat] = {\n",
    "        \"train_x\": train_x,\n",
    "        \"valid_x\": valid_x,\n",
    "        \"train_y\": train_y,\n",
    "        \"valid_y\": valid_y,\n",
    "        \"dtrain\": xgb.DMatrix(train_x, label=train_y),\n",
    "        \"dvalid\": xgb.DMatrix(valid_x, label=valid_y),\n",
    "    }\n",
    "    print(f\"{cat}: Train={train_x.shape}, Valid={valid_x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_correlation_with_target(df, target_col=\"units_sold\", save_path=None):\n",
    "    \"\"\"Plot correlation of features with target.\"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    correlations = numeric_df.corr()[target_col].drop(target_col).sort_values()\n",
    "    \n",
    "    colors = sns.diverging_palette(10, 130, as_cmap=True)\n",
    "    color_mapped = correlations.map(colors)\n",
    "    \n",
    "    sns.set_style(\"whitegrid\", {\"axes.facecolor\": \"#c2c4c2\"})\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.barh(correlations.index, correlations.values, color=color_mapped)\n",
    "    plt.title(f\"Correlation with {target_col}\", fontsize=14)\n",
    "    plt.xlabel(\"Correlation Coefficient\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "def plot_feature_importance(model, booster=\"gbtree\"):\n",
    "    \"\"\"Plot XGBoost feature importance.\"\"\"\n",
    "    importance_type = \"weight\" if booster == \"gblinear\" else \"gain\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    xgb.plot_importance(model, importance_type=importance_type, ax=ax)\n",
    "    plt.title(f\"Feature Importance ({importance_type})\")\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "def plot_residuals(model, dvalid, valid_y):\n",
    "    \"\"\"Plot residuals vs true values.\"\"\"\n",
    "    preds = model.predict(dvalid)\n",
    "    residuals = valid_y - preds\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(valid_y, residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "    plt.title(\"Residuals vs True Values\")\n",
    "    plt.xlabel(\"True Values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Optuna Objective Function with MLflow Child Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective(dtrain, dvalid, valid_y):\n",
    "    \"\"\"Create Optuna objective function for a specific dataset.\"\"\"\n",
    "    def objective(trial):\n",
    "        with mlflow.start_run(nested=True):\n",
    "            params = {\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"eval_metric\": \"rmse\",\n",
    "                \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "                \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "                \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "            }\n",
    "            \n",
    "            if params[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "                params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n",
    "                params[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "                params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "                params[\"grow_policy\"] = trial.suggest_categorical(\n",
    "                    \"grow_policy\", [\"depthwise\", \"lossguide\"]\n",
    "                )\n",
    "            \n",
    "            model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "            preds = model.predict(dvalid)\n",
    "            mse = mean_squared_error(valid_y, preds)\n",
    "            rmse = math.sqrt(mse)\n",
    "            \n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            \n",
    "        return mse\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def champion_callback(study, trial):\n",
    "    \"\"\"Log when a new best trial is found.\"\"\"\n",
    "    if study.best_trial.number == trial.number:\n",
    "        print(f\"  Trial {trial.number}: {trial.value:.4f} (new best)\")\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Run Hyperparameter Optimization Per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for each category\n",
    "category_results = {}\n",
    "\n",
    "for category, splits in category_splits.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training model for: {category.upper()}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    run_name = f\"{category}-optimization\"\n",
    "    \n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name, nested=True):\n",
    "        # Create objective for this category\n",
    "        objective = create_objective(\n",
    "            splits[\"dtrain\"],\n",
    "            splits[\"dvalid\"],\n",
    "            splits[\"valid_y\"],\n",
    "        )\n",
    "        \n",
    "        # Run optimization\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(objective, n_trials=n_trials, callbacks=[champion_callback])\n",
    "        \n",
    "        # Log best results\n",
    "        mlflow.log_params(study.best_params)\n",
    "        mlflow.log_metric(\"best_mse\", study.best_value)\n",
    "        mlflow.log_metric(\"best_rmse\", math.sqrt(study.best_value))\n",
    "        \n",
    "        mlflow.set_tags({\n",
    "            \"project\": \"Electronics Sales Prediction\",\n",
    "            \"category\": category,\n",
    "            \"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"xgboost\",\n",
    "        })\n",
    "        \n",
    "        # Train final model with best params\n",
    "        best_params = study.best_params.copy()\n",
    "        best_params[\"objective\"] = \"reg:squarederror\"\n",
    "        best_params[\"eval_metric\"] = \"rmse\"\n",
    "        best_model = xgb.train(best_params, splits[\"dtrain\"], num_boost_round=100)\n",
    "        \n",
    "        # Log plots\n",
    "        df_for_plot = category_datasets[category].copy()\n",
    "        corr_plot = plot_correlation_with_target(df_for_plot)\n",
    "        mlflow.log_figure(figure=corr_plot, artifact_file=\"correlation_plot.png\")\n",
    "        \n",
    "        importance_plot = plot_feature_importance(best_model, best_params.get(\"booster\", \"gbtree\"))\n",
    "        mlflow.log_figure(figure=importance_plot, artifact_file=\"feature_importances.png\")\n",
    "        \n",
    "        residual_plot = plot_residuals(best_model, splits[\"dvalid\"], splits[\"valid_y\"])\n",
    "        mlflow.log_figure(figure=residual_plot, artifact_file=\"residuals.png\")\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.xgboost.log_model(\n",
    "            xgb_model=best_model,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=splits[\"train_x\"].iloc[[0]],\n",
    "        )\n",
    "        \n",
    "        model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "        \n",
    "        # Store results\n",
    "        category_results[category] = {\n",
    "            \"study\": study,\n",
    "            \"best_model\": best_model,\n",
    "            \"model_uri\": model_uri,\n",
    "            \"best_mse\": study.best_value,\n",
    "            \"best_rmse\": math.sqrt(study.best_value),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{category} - Best RMSE: {math.sqrt(study.best_value):.4f}\")\n",
    "        print(f\"Model logged to: {model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY: Best Results Per Category\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for category, results in category_results.items():\n",
    "    study = results[\"study\"]\n",
    "    print(f\"\\n{category.upper()}\")\n",
    "    print(f\"  Best trial: {study.best_trial.number}\")\n",
    "    print(f\"  Best RMSE: {results['best_rmse']:.4f}\")\n",
    "    print(f\"  Best params:\")\n",
    "    for k, v in study.best_params.items():\n",
    "        print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Optuna Visualizations (Select a Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "# Select category to visualize\n",
    "viz_category = list(category_results.keys())[0]  # Change as needed\n",
    "study = category_results[viz_category][\"study\"]\n",
    "print(f\"Visualizing: {viz_category}\")\n",
    "\n",
    "fig = vis.plot_optimization_history(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vis.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vis.plot_parallel_coordinate(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vis.plot_slice(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Load and Use Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and use a specific category model\n",
    "test_category = list(category_results.keys())[0]\n",
    "model_uri = category_results[test_category][\"model_uri\"]\n",
    "splits = category_splits[test_category]\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "predictions = loaded_model.predict(splits[\"dvalid\"])\n",
    "\n",
    "result_df = splits[\"valid_x\"].copy()\n",
    "result_df[\"actual\"] = splits[\"valid_y\"].values\n",
    "result_df[\"predicted\"] = predictions\n",
    "\n",
    "print(f\"Category: {test_category}\")\n",
    "print(f\"Prediction stats:\")\n",
    "print(f\"  Mean: {predictions.mean():.2f}\")\n",
    "print(f\"  Std:  {predictions.std():.2f}\")\n",
    "result_df[[\"actual\", \"predicted\"]].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
